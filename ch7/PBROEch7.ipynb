{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-25T08:37:11.686603Z",
     "start_time": "2025-07-25T08:37:05.054673Z"
    }
   },
   "source": [
    "# 从数据库导入数据dfpbroech7\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 根据你的实际数据库信息填写\n",
    "username = \"panjinhe\"\n",
    "password = \"20020112p\"\n",
    "host = \"localhost\"\n",
    "port = \"5432\"\n",
    "database = \"pbroe\"\n",
    "\n",
    "# 定义要查询的表和schema\n",
    "table_name = 'pbroech6'\n",
    "schema_name = 'pbroe'\n",
    "\n",
    "# 定义日期范围\n",
    "start_date = '2005-04'\n",
    "end_date = '2025-03'\n",
    "\n",
    "# 构建连接字符串\n",
    "connection_string = f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# 创建引擎\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# 构建带有日期范围筛选的SQL查询语句\n",
    "# 这样可以在数据库层面直接过滤，效率更高\n",
    "sql_query = f\"\"\"\n",
    "SELECT * FROM {schema_name}.{table_name}\n",
    "WHERE \"trdmnt\" >= '{start_date}' AND \"trdmnt\" <= '{end_date}'\n",
    "\"\"\"\n",
    "# 使用 pd.read_sql_query 执行带有条件的查询\n",
    "dfpbroech7 = pd.read_sql_query(sql_query, engine)\n",
    "\n",
    "# print(\"\\n数据加载成功！\")\n",
    "# # --- 3. 显示数据信息 ---\n",
    "# print(\"\\nDataFrame Info:\")\n",
    "print(dfpbroech7.info())\n",
    "# print(\"\\nDataFrame Head (first 10 rows):\")\n",
    "#display(dfpbroech6.head(10))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 665563 entries, 0 to 665562\n",
      "Data columns (total 12 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   stkcd       665563 non-null  object \n",
      " 1   trdmnt      665563 non-null  object \n",
      " 2   accper      665563 non-null  object \n",
      " 3   shortname   665563 non-null  object \n",
      " 4   if_st       665563 non-null  int64  \n",
      " 5   indcd1      665563 non-null  object \n",
      " 6   indnme1     665563 non-null  object \n",
      " 7   price       665563 non-null  float64\n",
      " 8   market_cap  665563 non-null  float64\n",
      " 9   PB          663460 non-null  float64\n",
      " 10  roe_ttm     636635 non-null  float64\n",
      " 11  roic        655034 non-null  float64\n",
      "dtypes: float64(5), int64(1), object(6)\n",
      "memory usage: 60.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T07:11:20.981085Z",
     "start_time": "2025-07-25T07:11:15.007457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 假设您的主数据表 'dfpbroech7' 已经加载到内存中\n",
    "# 如果没有，请先加载：\n",
    "# dfpbroech7 = pd.read_csv('path_to_your_dfpbroech7_data.csv')\n",
    "\n",
    "# --- 步骤 1: 加载持仓数据 ---\n",
    "# 请确保文件路径正确\n",
    "holdings_path = 'E:\\\\PBROE\\\\ch7\\\\PBROE_5.0_from_3.1_TS_10M_holdings.csv'\n",
    "try:\n",
    "    # 明确指定stkcd为字符串类型，防止读取时丢失前面的0\n",
    "    holdings_df = pd.read_csv(holdings_path, dtype={'stkcd': str})\n",
    "    print(\"持仓文件加载成功。\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"错误：无法在路径 {holdings_path} 找到文件。请检查路径是否正确。\")\n",
    "    # 如果文件未找到，则停止执行后续代码\n",
    "    # 在实际的notebook中，后续代码会因为holdings_df未定义而报错\n",
    "    holdings_df = None\n",
    "\n",
    "if holdings_df is not None:\n",
    "    # --- 步骤 2: 准备用于合并的两个DataFrame ---\n",
    "\n",
    "    # 准备 holdings_df\n",
    "    # a. 为了方便，重命名中文列名\n",
    "    holdings_df.rename(columns={'调入日期': 'holding_date'}, inplace=True)\n",
    "\n",
    "    # b. 将 'holding_date' 列转换为日期时间对象\n",
    "    holdings_df['holding_date'] = pd.to_datetime(holdings_df['holding_date'])\n",
    "\n",
    "    # c. 创建一个 '年-月' 格式的合并键\n",
    "    holdings_df['merge_month'] = holdings_df['holding_date'].dt.strftime('%Y-%m')\n",
    "\n",
    "    # d. 确保stkcd是6位字符串，不足则在前面补0\n",
    "    holdings_df['stkcd'] = holdings_df['stkcd'].str.zfill(6)\n",
    "\n",
    "\n",
    "    # 准备 dfpbroech7\n",
    "    # a. 确保 'stkcd' 是6位字符串\n",
    "    dfpbroech7['stkcd'] = dfpbroech7['stkcd'].astype(str).str.zfill(6)\n",
    "\n",
    "    # b. 将 'trdmnt' 列转换为日期时间对象\n",
    "    dfpbroech7['trdmnt'] = pd.to_datetime(dfpbroech7['trdmnt'])\n",
    "\n",
    "    # c. 创建一个 '年-月' 格式的合并键\n",
    "    dfpbroech7['merge_month'] = dfpbroech7['trdmnt'].dt.strftime('%Y-%m')\n",
    "\n",
    "\n",
    "    # --- 步骤 3: 执行合并 ---\n",
    "    # 使用左连接（left merge），保留dfpbroech7的所有行\n",
    "    # 将holdings_df的数据匹配到dfpbroech7中\n",
    "    merged_df = pd.merge(dfpbroech7,\n",
    "                         holdings_df,\n",
    "                         on=['stkcd', 'merge_month'],\n",
    "                         how='right')\n",
    "\n",
    "    # --- 步骤 4: 验证结果 ---\n",
    "    print(\"\\n合并完成。以下是合并后数据的前5行预览：\")\n",
    "    print(merged_df.head())\n",
    "\n",
    "    print(\"\\n合并后DataFrame的基本信息：\")\n",
    "    merged_df.info()\n",
    "\n",
    "    # 检查有多少行成功匹配到了持仓信息\n",
    "    # 通过检查合并过来的'holding_date'列是否非空来判断\n",
    "    matched_rows = merged_df['holding_date'].notna().sum()\n",
    "    total_rows = len(merged_df)\n",
    "    print(f\"\\n成功将持仓信息匹配到 {matched_rows} / {total_rows} 行。\")\n",
    "\n",
    "    # 您可以检查一下没有匹配上的情况，例如：\n",
    "    # unmatched_sample = merged_df[merged_df['holding_date'].isna()].head()\n",
    "    # print(\"\\n未匹配上的数据示例：\")\n",
    "    # print(unmatched_sample)\n",
    "\n"
   ],
   "id": "6748bd8c852d759e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "持仓文件加载成功。\n",
      "\n",
      "合并完成。以下是合并后数据的前5行预览：\n",
      "    stkcd     trdmnt      accper shortname_x  if_st indcd1     indnme1_x  \\\n",
      "0  000027 2010-05-01  2009-12-31        深圳能源    0.0    D44   电力、热力生产和供应业   \n",
      "1  000155 2010-05-01  2009-12-31        川化股份    0.0    C26  化学原料和化学制品制造业   \n",
      "2  000402 2010-05-01  2009-12-31         金融街    0.0    K70          房地产业   \n",
      "3  000600 2010-05-01  2009-12-31        建投能源    0.0    D44   电力、热力生产和供应业   \n",
      "4  000667 2010-05-01  2009-12-31        名流置业    0.0    K70          房地产业   \n",
      "\n",
      "   price    market_cap      PB_x  ...  merge_month  holding_date shortname_y  \\\n",
      "0  10.50  2.312620e+10  0.356866  ...      2010-05    2010-05-01        深圳能源   \n",
      "1   6.37  2.993900e+09  0.397018  ...      2010-05    2010-05-01        川化股份   \n",
      "2   8.22  2.039557e+10  0.317574  ...      2010-05    2010-05-01         金融街   \n",
      "3   5.21  4.760169e+09  0.295477  ...      2010-05    2010-05-01        建投能源   \n",
      "4   6.97  9.389662e+09  0.455745  ...      2010-05    2010-05-01        名流置业   \n",
      "\n",
      "      indnme1_y    ROEttm      PB_y  residual_zscore  residual_quantile_10m  \\\n",
      "0   电力、热力生产和供应业  0.144948  0.406488        -2.442703                    0.1   \n",
      "1  化学原料和化学制品制造业  0.022837  0.451241        -2.647801                    0.1   \n",
      "2          房地产业  0.109621  0.342300        -2.061502                    0.1   \n",
      "3   电力、热力生产和供应业  0.046273  0.347086        -2.340790                    0.1   \n",
      "4          房地产业  0.033227  0.493669        -1.726599                    0.1   \n",
      "\n",
      "   residual_quantile_20m  residual_quantile_50m  \n",
      "0                   0.05               0.021739  \n",
      "1                   0.05               0.020408  \n",
      "2                   0.05               0.020408  \n",
      "3                   0.05               0.020408  \n",
      "4                   0.20               0.081633  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "合并后DataFrame的基本信息：\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20671 entries, 0 to 20670\n",
      "Data columns (total 22 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   stkcd                  20671 non-null  object        \n",
      " 1   trdmnt                 20441 non-null  datetime64[ns]\n",
      " 2   accper                 20441 non-null  object        \n",
      " 3   shortname_x            20441 non-null  object        \n",
      " 4   if_st                  20441 non-null  float64       \n",
      " 5   indcd1                 20441 non-null  object        \n",
      " 6   indnme1_x              20441 non-null  object        \n",
      " 7   price                  20441 non-null  float64       \n",
      " 8   market_cap             20441 non-null  float64       \n",
      " 9   PB_x                   20432 non-null  float64       \n",
      " 10  roe_ttm                20441 non-null  float64       \n",
      " 11  roic                   20309 non-null  float64       \n",
      " 12  merge_month            20671 non-null  object        \n",
      " 13  holding_date           20671 non-null  datetime64[ns]\n",
      " 14  shortname_y            20671 non-null  object        \n",
      " 15  indnme1_y              20671 non-null  object        \n",
      " 16  ROEttm                 20671 non-null  float64       \n",
      " 17  PB_y                   20671 non-null  float64       \n",
      " 18  residual_zscore        20671 non-null  float64       \n",
      " 19  residual_quantile_10m  20671 non-null  float64       \n",
      " 20  residual_quantile_20m  20671 non-null  float64       \n",
      " 21  residual_quantile_50m  20671 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(12), object(8)\n",
      "memory usage: 3.5+ MB\n",
      "\n",
      "成功将持仓信息匹配到 20671 / 20671 行。\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T07:15:54.588633Z",
     "start_time": "2025-07-25T07:15:42.687437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 用ROIC区分和回测\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "\n",
    "# --- 步骤 0: 配置参数 ---\n",
    "# 请根据您的文件存放位置修改以下路径\n",
    "RETURNS_FILE = Path(\"E:/PBROE/data/TRDNEW_Mnth.csv\")\n",
    "BENCHMARK_FILE = Path(\"E:/PBROE/data/benchmark_indices.csv\")\n",
    "# 新增：定义结果输出文件夹\n",
    "OUTPUT_DIR = Path(\"E:/PBROE/ch7/backtest_results\")\n",
    "\n",
    "# 回测参数\n",
    "START_DATE = \"2010-05-01\"\n",
    "END_DATE = \"2025-04-30\"\n",
    "BENCHMARK_CODE = '000300'\n",
    "RISK_FREE_RATE = 0.03\n",
    "# 用于分组的分位数，例如0.3代表选取前30%和后30%\n",
    "QUANTILE_THRESHOLD = 0.8\n",
    "\n",
    "# 确保 'merged_df' 已经存在于您的Notebook环境中\n",
    "if 'merged_df' not in locals():\n",
    "    print(\"错误：'merged_df' 不存在。请先运行数据合并的代码。\")\n",
    "    # 此处可以添加加载 merged_df 的代码作为备用\n",
    "    # merged_df = pd.read_csv('path_to_your_merged_df.csv', dtype={'stkcd': str})\n",
    "    # merged_df['trdmnt'] = pd.to_datetime(merged_df['trdmnt'])\n",
    "\n",
    "\n",
    "# --- 步骤 1: 调用回测引擎的核心函数 ---\n",
    "\n",
    "def build_portfolio_by_quantile(\n",
    "    holdings_df: pd.DataFrame,\n",
    "    factor_col: str,\n",
    "    quantile: float,\n",
    "    select_top: bool\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    根据指定因子和分位数构建投资组合。\n",
    "    \"\"\"\n",
    "    df_filtered = holdings_df.dropna(subset=[factor_col]).copy()\n",
    "    selections_dict = {}\n",
    "\n",
    "    for date, group in df_filtered.groupby('trdmnt'):\n",
    "        try:\n",
    "            if select_top:\n",
    "                # 高分组\n",
    "                threshold = group[factor_col].quantile(1 - quantile)\n",
    "                selected_stocks = set(group[group[factor_col] >= threshold]['stkcd'])\n",
    "            else:\n",
    "                # 低分组\n",
    "                threshold = group[factor_col].quantile(quantile)\n",
    "                selected_stocks = set(group[group[factor_col] <= threshold]['stkcd'])\n",
    "\n",
    "            if selected_stocks:\n",
    "                selections_dict[pd.to_datetime(date)] = selected_stocks\n",
    "        except Exception:\n",
    "            continue\n",
    "    return selections_dict\n",
    "\n",
    "\n",
    "def run_single_strategy_backtest(\n",
    "    strategy_name: str,\n",
    "    selections: dict,\n",
    "    returns_df: pd.DataFrame,\n",
    "    start_date: str,\n",
    "    end_date: str\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    对单个策略执行向量化回测。\n",
    "    \"\"\"\n",
    "    backtest_months = pd.to_datetime(pd.date_range(start_date, end_date, freq='MS'))\n",
    "    portfolio_map = pd.Series(index=backtest_months, dtype='object')\n",
    "    rebalance_dates = sorted(selections.keys())\n",
    "\n",
    "    if rebalance_dates:\n",
    "        selections_series = pd.Series(selections)\n",
    "        portfolio_map = selections_series.reindex(backtest_months, method='ffill')\n",
    "\n",
    "    returns_df_indexed = returns_df.set_index(['Trdmnt', 'Stkcd'])\n",
    "    monthly_returns = []\n",
    "    for month, stocks in portfolio_map.items():\n",
    "        if not isinstance(stocks, set) or not stocks:\n",
    "            monthly_returns.append(0.0)\n",
    "            continue\n",
    "        month_str = month.strftime('%Y-%m')\n",
    "        try:\n",
    "            relevant_returns = returns_df_indexed.loc[month_str]\n",
    "            avg_return = relevant_returns[relevant_returns.index.isin(stocks)]['Mretwd'].mean()\n",
    "            monthly_returns.append(avg_return if pd.notna(avg_return) else 0.0)\n",
    "        except KeyError:\n",
    "            monthly_returns.append(0.0)\n",
    "\n",
    "    return pd.Series(monthly_returns, index=backtest_months, name=f\"return_{strategy_name}\")\n",
    "\n",
    "\n",
    "def calculate_and_save_performance(\n",
    "    all_returns_df: pd.DataFrame,\n",
    "    benchmark_df: pd.DataFrame,\n",
    "    risk_free_rate: float,\n",
    "    output_dir: Path\n",
    "):\n",
    "    \"\"\"\n",
    "    计算并保存多个策略的详细绩效指标到CSV文件。\n",
    "    \"\"\"\n",
    "    print(\"\\n--- 各策略绩效对比报告 ---\")\n",
    "    # 确保输出目录存在\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    returns_output_file = output_dir / 'roic_groups_monthly_returns.csv'\n",
    "    performance_output_file = output_dir / 'roic_groups_performance_summary.csv'\n",
    "\n",
    "    results = all_returns_df.join(benchmark_df.set_index('date'), how='left').fillna(0)\n",
    "    all_metrics = []\n",
    "    total_months = len(results)\n",
    "\n",
    "    annualized_benchmark_return = (1 + results['benchmark_return']).prod() ** (12 / total_months) - 1\n",
    "\n",
    "    strategy_cols = [col for col in results.columns if col.startswith('return_')]\n",
    "    for return_col in strategy_cols:\n",
    "        strategy_name = return_col.replace('return_', '')\n",
    "        cum_col = f'cum_{strategy_name}'\n",
    "        results[cum_col] = (1 + results[return_col]).cumprod()\n",
    "\n",
    "        final_return = results[cum_col].iloc[-1]\n",
    "        annualized_return = final_return ** (12 / total_months) - 1\n",
    "        annualized_volatility = results[return_col].std() * np.sqrt(12)\n",
    "        sharpe_ratio = (annualized_return - risk_free_rate) / annualized_volatility if annualized_volatility != 0 else 0\n",
    "\n",
    "        rolling_max = results[cum_col].expanding().max()\n",
    "        drawdown = (results[cum_col] - rolling_max) / rolling_max\n",
    "        max_drawdown = drawdown.min()\n",
    "\n",
    "        excess_return = results[return_col] - results['benchmark_return']\n",
    "        annualized_excess_return = annualized_return - annualized_benchmark_return\n",
    "        tracking_error = excess_return.std() * np.sqrt(12)\n",
    "        information_ratio = annualized_excess_return / tracking_error if tracking_error != 0 else 0\n",
    "\n",
    "        metrics = {\n",
    "            '策略名称': strategy_name,\n",
    "            '年化收益率': annualized_return, '年化波动率': annualized_volatility, '夏普比率': sharpe_ratio,\n",
    "            '最大回撤': max_drawdown, '累计收益率': final_return - 1,\n",
    "            '年化超额收益率': annualized_excess_return, '信息比率': information_ratio, '跟踪误差': tracking_error,\n",
    "        }\n",
    "        all_metrics.append(metrics)\n",
    "\n",
    "    performance_df = pd.DataFrame(all_metrics).set_index('策略名称')\n",
    "    performance_df.loc['基准 (沪深300)', '年化收益率'] = annualized_benchmark_return\n",
    "\n",
    "    # 保存月度收益率文件\n",
    "    results.to_csv(returns_output_file, encoding='utf-8-sig', float_format='%.6f')\n",
    "    print(f\"\\n所有策略的月度收益数据已保存至: {returns_output_file}\")\n",
    "\n",
    "    # 格式化并保存绩效汇总文件\n",
    "    formatted_df = performance_df.copy()\n",
    "    percent_cols = ['年化收益率', '年化波动率', '最大回撤', '累计收益率', '年化超额收益率', '跟踪误差']\n",
    "    for col in percent_cols:\n",
    "        formatted_df[col] = formatted_df[col].apply(lambda x: f\"{x:.2%}\" if pd.notna(x) else '-')\n",
    "    for col in ['夏普比率', '信息比率']:\n",
    "        formatted_df[col] = formatted_df[col].apply(lambda x: f\"{x:.2f}\" if pd.notna(x) else '-')\n",
    "\n",
    "    formatted_df.to_csv(performance_output_file, encoding='utf-8-sig')\n",
    "    print(f\"所有策略的格式化绩效评估报告已保存至: {performance_output_file}\")\n",
    "\n",
    "    print(\"\\n--- 绩效简报 ---\")\n",
    "    print(formatted_df.to_string())\n",
    "\n",
    "\n",
    "# --- 步骤 2: 执行主流程 ---\n",
    "try:\n",
    "    # 1. 加载公用数据\n",
    "    print(\"--- 正在加载公用数据 (股票收益率, 基准指数)... ---\")\n",
    "    returns_df = pd.read_csv(RETURNS_FILE)\n",
    "    returns_df['Stkcd'] = returns_df['Stkcd'].astype(str).str.zfill(6)\n",
    "    returns_df['Trdmnt'] = pd.to_datetime(returns_df['Trdmnt']).dt.strftime('%Y-%m')\n",
    "    returns_df['Mretwd'] = pd.to_numeric(returns_df['Mretwd'], errors='coerce').fillna(0)\n",
    "\n",
    "    all_benchmarks_df = pd.read_csv(BENCHMARK_FILE)\n",
    "    benchmark_df = all_benchmarks_df[all_benchmarks_df['Indexcd'].astype(str).str.zfill(6) == BENCHMARK_CODE].copy()\n",
    "    benchmark_df['date'] = pd.to_datetime(benchmark_df['Month'], format='%Y-%m')\n",
    "    benchmark_df.rename(columns={'Idxrtn': 'benchmark_return'}, inplace=True)\n",
    "    benchmark_df = benchmark_df[['date', 'benchmark_return']]\n",
    "    print(\"数据加载完成。\")\n",
    "\n",
    "    # 2. 构建高、低ROIC投资组合\n",
    "    print(f\"\\n--- 正在构建投资组合 (分位数阈值: {QUANTILE_THRESHOLD})... ---\")\n",
    "    high_roic_selections = build_portfolio_by_quantile(merged_df, 'roic', QUANTILE_THRESHOLD, select_top=True)\n",
    "    low_roic_selections = build_portfolio_by_quantile(merged_df, 'roic', QUANTILE_THRESHOLD, select_top=False)\n",
    "    print(\"投资组合构建完成。\")\n",
    "    print(f\"高ROIC组共构建了 {len(high_roic_selections)} 个调仓期。\")\n",
    "    print(f\"低ROIC组共构建了 {len(low_roic_selections)} 个调仓期。\")\n",
    "\n",
    "    # 3. 运行回测\n",
    "    print(\"\\n--- 正在运行回测... ---\")\n",
    "    high_roic_returns = run_single_strategy_backtest(\"High_ROIC\", high_roic_selections, returns_df, START_DATE, END_DATE)\n",
    "    low_roic_returns = run_single_strategy_backtest(\"Low_ROIC\", low_roic_selections, returns_df, START_DATE, END_DATE)\n",
    "    print(\"回测完成。\")\n",
    "\n",
    "    # 4. 合并收益并计算绩效，然后保存到文件\n",
    "    all_returns_df = pd.concat([high_roic_returns, low_roic_returns], axis=1)\n",
    "    calculate_and_save_performance(all_returns_df, benchmark_df, RISK_FREE_RATE, OUTPUT_DIR)\n",
    "\n",
    "    print(\"\\n--- 所有任务完成 ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n执行过程中出现严重错误: {e}\")\n",
    "    traceback.print_exc()"
   ],
   "id": "821d35ba5c9124d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 正在加载公用数据 (股票收益率, 基准指数)... ---\n",
      "数据加载完成。\n",
      "\n",
      "--- 正在构建投资组合 (分位数阈值: 0.8)... ---\n",
      "投资组合构建完成。\n",
      "高ROIC组共构建了 179 个调仓期。\n",
      "低ROIC组共构建了 179 个调仓期。\n",
      "\n",
      "--- 正在运行回测... ---\n",
      "回测完成。\n",
      "\n",
      "--- 各策略绩效对比报告 ---\n",
      "\n",
      "所有策略的月度收益数据已保存至: E:\\PBROE\\ch7\\backtest_results\\roic_groups_monthly_returns.csv\n",
      "所有策略的格式化绩效评估报告已保存至: E:\\PBROE\\ch7\\backtest_results\\roic_groups_performance_summary.csv\n",
      "\n",
      "--- 绩效简报 ---\n",
      "             年化收益率   年化波动率  夏普比率     最大回撤     累计收益率 年化超额收益率  信息比率    跟踪误差\n",
      "策略名称                                                                     \n",
      "High_ROIC   20.55%  27.79%  0.63  -33.88%  1550.09%  19.16%  1.03  18.66%\n",
      "Low_ROIC    20.84%  27.88%  0.64  -37.81%  1611.41%  19.46%  1.07  18.16%\n",
      "基准 (沪深300)   1.39%       -     -        -         -       -     -       -\n",
      "\n",
      "--- 所有任务完成 ---\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T13:19:14.442840Z",
     "start_time": "2025-07-25T13:19:13.041554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "\n",
    "# =================================================================== #\n",
    "#                           【1. 配置区域】                           #\n",
    "# =================================================================== #\n",
    "# 假设 dfpbroech7 变量已在之前的单元格中成功创建\n",
    "\n",
    "# --- 输出文件配置 (可选，如果需要保存结果) ---\n",
    "OUTPUT_DIR = Path(r'E:\\PBROE\\ch7\\analysis_results')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PARAMS_FILENAME = 'annual_regression_parameters.csv'\n",
    "\n",
    "\n",
    "# =================================================================== #\n",
    "#                       【2. 数据清洗与预处理】                       #\n",
    "# =================================================================== #\n",
    "print(\"--- 步骤 1: 数据清洗与预处理 ---\")\n",
    "\n",
    "# 确保 dfpbroech7 存在\n",
    "if 'dfpbroech7' not in locals():\n",
    "    print(\"错误: 变量 'dfpbroech7' 未定义。请先运行数据加载的代码单元格。\")\n",
    "    # 为了能独立运行，可以添加加载代码\n",
    "    # dfpbroech7 = pd.read_csv('path_to_your_data.csv')\n",
    "    df_clean = pd.DataFrame() # 创建一个空的DataFrame以避免后续代码报错\n",
    "else:\n",
    "    df = dfpbroech7.copy()\n",
    "\n",
    "    # 1. 剔除ST,*ST股票 (假设 if_st=1 为ST)\n",
    "    df = df[df['if_st'] != 1]\n",
    "\n",
    "    # 2. 【回归模型特定清洗】剔除不符合回归条件的样本\n",
    "    df = df[(df['PB'] > 0) &\n",
    "            (df['roe_ttm'] <= 0.5) & (df['roe_ttm'] >= -0.1) &\n",
    "            (df['roic'] <= 0.5) & (df['roic'] >= -0.1)]\n",
    "\n",
    "    # 3. 剔除关键指标为空的记录\n",
    "    df.dropna(subset=['roe_ttm', 'roic', 'PB', 'trdmnt'], inplace=True)\n",
    "\n",
    "    # 4. 计算因变量和自变量\n",
    "    df['lnPB'] = np.log(df['PB'])\n",
    "    df['leverage_spread'] = df['roe_ttm'] - df['roic']\n",
    "\n",
    "    # 5. 创建年份列用于年度回归\n",
    "    df['year'] = pd.to_datetime(df['trdmnt'], format='%Y-%m').dt.year\n",
    "\n",
    "    df_clean = df\n",
    "    print(f\"数据清洗后，剩余 {len(df_clean)} 条有效记录用于回归分析。\")\n",
    "\n",
    "\n",
    "# =================================================================== #\n",
    "#                       【3. 全样本回归分析】                         #\n",
    "# =================================================================== #\n",
    "if not df_clean.empty:\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"【全样本回归分析】: ln(P/B) ~ 1 + roic + leverage_spread\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        # 准备 Y 和 X\n",
    "        y_full = df_clean['lnPB']\n",
    "        X_full = df_clean[['roic', 'leverage_spread']]\n",
    "        X_full = sm.add_constant(X_full)\n",
    "\n",
    "        # 执行OLS回归\n",
    "        model_full = sm.OLS(y_full, X_full, missing='drop').fit()\n",
    "\n",
    "        # 打印详细的回归结果摘要\n",
    "        print(model_full.summary())\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"全样本回归失败: {e}\")\n",
    "\n",
    "\n",
    "# =================================================================== #\n",
    "#                       【4. 年度滚动回归分析】                       #\n",
    "# =================================================================== #\n",
    "if not df_clean.empty:\n",
    "    print(\"\\n\\n\" + \"=\"*80)\n",
    "    print(\"【年度滚动回归分析】\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    annual_results = []\n",
    "\n",
    "    # 按年份分组\n",
    "    for year, group in df_clean.groupby('year'):\n",
    "        # 样本量过少则跳过\n",
    "        if len(group) < 100:\n",
    "            print(f\"年份 {year}: 样本量过少 ({len(group)}), 已跳过。\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 准备当年的 Y 和 X\n",
    "            y_year = group['lnPB']\n",
    "            X_year = group[['roic', 'leverage_spread']]\n",
    "            X_year = sm.add_constant(X_year)\n",
    "\n",
    "            # 执行OLS回归\n",
    "            model_year = sm.OLS(y_year, X_year, missing='drop').fit()\n",
    "\n",
    "            # 提取需要的参数\n",
    "            params = {\n",
    "                'year': year,\n",
    "                'n_obs': model_year.nobs,\n",
    "                'r_squared': model_year.rsquared_adj,\n",
    "                'beta_0_const': model_year.params['const'],\n",
    "                'p_val_const': model_year.pvalues['const'],\n",
    "                'beta_1_roic': model_year.params['roic'],\n",
    "                'p_val_roic': model_year.pvalues['roic'],\n",
    "                'beta_2_leverage': model_year.params['leverage_spread'],\n",
    "                'p_val_leverage': model_year.pvalues['leverage_spread']\n",
    "            }\n",
    "            annual_results.append(params)\n",
    "            print(f\"年份 {year}: 回归计算完成。\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"年份 {year}: 回归失败 - {e}\")\n",
    "\n",
    "    # 将年度结果整理成DataFrame\n",
    "    if annual_results:\n",
    "        annual_params_df = pd.DataFrame(annual_results).set_index('year')\n",
    "\n",
    "        print(\"\\n--- 年度回归参数汇总表 ---\")\n",
    "        # 使用 display 函数在Jupyter中获得更好的表格显示效果\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            display(annual_params_df.style.format({\n",
    "                'n_obs': '{:,.0f}',\n",
    "                'r_squared': '{:.3f}',\n",
    "                'beta_0_const': '{:.3f}',\n",
    "                'p_val_const': '{:.3f}',\n",
    "                'beta_1_roic': '{:.3f}',\n",
    "                'p_val_roic': '{:.3f}',\n",
    "                'beta_2_leverage': '{:.3f}',\n",
    "                'p_val_leverage': '{:.3f}'\n",
    "            }))\n",
    "        except (ImportError, NameError):\n",
    "            print(annual_params_df.to_string(float_format=\"%.3f\"))\n",
    "\n",
    "        # 保存到CSV文件\n",
    "        output_path = OUTPUT_DIR / PARAMS_FILENAME\n",
    "        annual_params_df.to_csv(output_path, encoding='utf-8-sig', float_format='%.6f')\n",
    "        print(f\"\\n年度回归参数已保存至: '{output_path}'\")\n",
    "\n",
    "    else:\n",
    "        print(\"未能计算出任何年度回归结果。\")\n",
    "\n"
   ],
   "id": "6e8a848c70a5d945",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 步骤 1: 数据清洗与预处理 ---\n",
      "数据清洗后，剩余 582202 条有效记录用于回归分析。\n",
      "\n",
      "\n",
      "================================================================================\n",
      "【全样本回归分析】: ln(P/B) ~ 1 + roic + leverage_spread\n",
      "================================================================================\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   lnPB   R-squared:                       0.046\n",
      "Model:                            OLS   Adj. R-squared:                  0.046\n",
      "Method:                 Least Squares   F-statistic:                 1.393e+04\n",
      "Date:                Fri, 25 Jul 2025   Prob (F-statistic):               0.00\n",
      "Time:                        21:19:13   Log-Likelihood:            -6.5470e+05\n",
      "No. Observations:              582202   AIC:                         1.309e+06\n",
      "Df Residuals:                  582199   BIC:                         1.309e+06\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const               0.6988      0.001    483.401      0.000       0.696       0.702\n",
      "roic                2.7926      0.026    107.160      0.000       2.741       2.844\n",
      "leverage_spread     1.5446      0.017     91.218      0.000       1.511       1.578\n",
      "==============================================================================\n",
      "Omnibus:                    11751.115   Durbin-Watson:                   0.134\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            24056.610\n",
      "Skew:                           0.094   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.978   Cond. No.                         27.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "【年度滚动回归分析】\n",
      "================================================================================\n",
      "年份 2005: 回归计算完成。\n",
      "年份 2006: 回归计算完成。\n",
      "年份 2007: 回归计算完成。\n",
      "年份 2008: 回归计算完成。\n",
      "年份 2009: 回归计算完成。\n",
      "年份 2010: 回归计算完成。\n",
      "年份 2011: 回归计算完成。\n",
      "年份 2012: 回归计算完成。\n",
      "年份 2013: 回归计算完成。\n",
      "年份 2014: 回归计算完成。\n",
      "年份 2015: 回归计算完成。\n",
      "年份 2016: 回归计算完成。\n",
      "年份 2017: 回归计算完成。\n",
      "年份 2018: 回归计算完成。\n",
      "年份 2019: 回归计算完成。\n",
      "年份 2020: 回归计算完成。\n",
      "年份 2021: 回归计算完成。\n",
      "年份 2022: 回归计算完成。\n",
      "年份 2023: 回归计算完成。\n",
      "年份 2024: 回归计算完成。\n",
      "年份 2025: 回归计算完成。\n",
      "\n",
      "--- 年度回归参数汇总表 ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x3a957fb0>"
      ],
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_8fb44\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_8fb44_level0_col0\" class=\"col_heading level0 col0\" >n_obs</th>\n",
       "      <th id=\"T_8fb44_level0_col1\" class=\"col_heading level0 col1\" >r_squared</th>\n",
       "      <th id=\"T_8fb44_level0_col2\" class=\"col_heading level0 col2\" >beta_0_const</th>\n",
       "      <th id=\"T_8fb44_level0_col3\" class=\"col_heading level0 col3\" >p_val_const</th>\n",
       "      <th id=\"T_8fb44_level0_col4\" class=\"col_heading level0 col4\" >beta_1_roic</th>\n",
       "      <th id=\"T_8fb44_level0_col5\" class=\"col_heading level0 col5\" >p_val_roic</th>\n",
       "      <th id=\"T_8fb44_level0_col6\" class=\"col_heading level0 col6\" >beta_2_leverage</th>\n",
       "      <th id=\"T_8fb44_level0_col7\" class=\"col_heading level0 col7\" >p_val_leverage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >year</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "      <th class=\"blank col7\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row0\" class=\"row_heading level0 row0\" >2005</th>\n",
       "      <td id=\"T_8fb44_row0_col0\" class=\"data row0 col0\" >9,726</td>\n",
       "      <td id=\"T_8fb44_row0_col1\" class=\"data row0 col1\" >0.060</td>\n",
       "      <td id=\"T_8fb44_row0_col2\" class=\"data row0 col2\" >-0.475</td>\n",
       "      <td id=\"T_8fb44_row0_col3\" class=\"data row0 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row0_col4\" class=\"data row0 col4\" >1.109</td>\n",
       "      <td id=\"T_8fb44_row0_col5\" class=\"data row0 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row0_col6\" class=\"data row0 col6\" >2.413</td>\n",
       "      <td id=\"T_8fb44_row0_col7\" class=\"data row0 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row1\" class=\"row_heading level0 row1\" >2006</th>\n",
       "      <td id=\"T_8fb44_row1_col0\" class=\"data row1 col0\" >12,894</td>\n",
       "      <td id=\"T_8fb44_row1_col1\" class=\"data row1 col1\" >0.073</td>\n",
       "      <td id=\"T_8fb44_row1_col2\" class=\"data row1 col2\" >-0.126</td>\n",
       "      <td id=\"T_8fb44_row1_col3\" class=\"data row1 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row1_col4\" class=\"data row1 col4\" >3.962</td>\n",
       "      <td id=\"T_8fb44_row1_col5\" class=\"data row1 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row1_col6\" class=\"data row1 col6\" >1.694</td>\n",
       "      <td id=\"T_8fb44_row1_col7\" class=\"data row1 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row2\" class=\"row_heading level0 row2\" >2007</th>\n",
       "      <td id=\"T_8fb44_row2_col0\" class=\"data row2 col0\" >13,396</td>\n",
       "      <td id=\"T_8fb44_row2_col1\" class=\"data row2 col1\" >0.070</td>\n",
       "      <td id=\"T_8fb44_row2_col2\" class=\"data row2 col2\" >0.761</td>\n",
       "      <td id=\"T_8fb44_row2_col3\" class=\"data row2 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row2_col4\" class=\"data row2 col4\" >2.577</td>\n",
       "      <td id=\"T_8fb44_row2_col5\" class=\"data row2 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row2_col6\" class=\"data row2 col6\" >2.101</td>\n",
       "      <td id=\"T_8fb44_row2_col7\" class=\"data row2 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row3\" class=\"row_heading level0 row3\" >2008</th>\n",
       "      <td id=\"T_8fb44_row3_col0\" class=\"data row3 col0\" >14,718</td>\n",
       "      <td id=\"T_8fb44_row3_col1\" class=\"data row3 col1\" >0.057</td>\n",
       "      <td id=\"T_8fb44_row3_col2\" class=\"data row3 col2\" >0.411</td>\n",
       "      <td id=\"T_8fb44_row3_col3\" class=\"data row3 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row3_col4\" class=\"data row3 col4\" >4.911</td>\n",
       "      <td id=\"T_8fb44_row3_col5\" class=\"data row3 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row3_col6\" class=\"data row3 col6\" >-0.477</td>\n",
       "      <td id=\"T_8fb44_row3_col7\" class=\"data row3 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row4\" class=\"row_heading level0 row4\" >2009</th>\n",
       "      <td id=\"T_8fb44_row4_col0\" class=\"data row4 col0\" >15,327</td>\n",
       "      <td id=\"T_8fb44_row4_col1\" class=\"data row4 col1\" >0.018</td>\n",
       "      <td id=\"T_8fb44_row4_col2\" class=\"data row4 col2\" >0.901</td>\n",
       "      <td id=\"T_8fb44_row4_col3\" class=\"data row4 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row4_col4\" class=\"data row4 col4\" >0.743</td>\n",
       "      <td id=\"T_8fb44_row4_col5\" class=\"data row4 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row4_col6\" class=\"data row4 col6\" >1.036</td>\n",
       "      <td id=\"T_8fb44_row4_col7\" class=\"data row4 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row5\" class=\"row_heading level0 row5\" >2010</th>\n",
       "      <td id=\"T_8fb44_row5_col0\" class=\"data row5 col0\" >16,483</td>\n",
       "      <td id=\"T_8fb44_row5_col1\" class=\"data row5 col1\" >0.021</td>\n",
       "      <td id=\"T_8fb44_row5_col2\" class=\"data row5 col2\" >1.091</td>\n",
       "      <td id=\"T_8fb44_row5_col3\" class=\"data row5 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row5_col4\" class=\"data row5 col4\" >2.249</td>\n",
       "      <td id=\"T_8fb44_row5_col5\" class=\"data row5 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row5_col6\" class=\"data row5 col6\" >0.290</td>\n",
       "      <td id=\"T_8fb44_row5_col7\" class=\"data row5 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row6\" class=\"row_heading level0 row6\" >2011</th>\n",
       "      <td id=\"T_8fb44_row6_col0\" class=\"data row6 col0\" >20,075</td>\n",
       "      <td id=\"T_8fb44_row6_col1\" class=\"data row6 col1\" >0.021</td>\n",
       "      <td id=\"T_8fb44_row6_col2\" class=\"data row6 col2\" >0.886</td>\n",
       "      <td id=\"T_8fb44_row6_col3\" class=\"data row6 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row6_col4\" class=\"data row6 col4\" >2.183</td>\n",
       "      <td id=\"T_8fb44_row6_col5\" class=\"data row6 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row6_col6\" class=\"data row6 col6\" >0.425</td>\n",
       "      <td id=\"T_8fb44_row6_col7\" class=\"data row6 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row7\" class=\"row_heading level0 row7\" >2012</th>\n",
       "      <td id=\"T_8fb44_row7_col0\" class=\"data row7 col0\" >23,779</td>\n",
       "      <td id=\"T_8fb44_row7_col1\" class=\"data row7 col1\" >0.052</td>\n",
       "      <td id=\"T_8fb44_row7_col2\" class=\"data row7 col2\" >0.458</td>\n",
       "      <td id=\"T_8fb44_row7_col3\" class=\"data row7 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row7_col4\" class=\"data row7 col4\" >3.397</td>\n",
       "      <td id=\"T_8fb44_row7_col5\" class=\"data row7 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row7_col6\" class=\"data row7 col6\" >0.716</td>\n",
       "      <td id=\"T_8fb44_row7_col7\" class=\"data row7 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row8\" class=\"row_heading level0 row8\" >2013</th>\n",
       "      <td id=\"T_8fb44_row8_col0\" class=\"data row8 col0\" >26,568</td>\n",
       "      <td id=\"T_8fb44_row8_col1\" class=\"data row8 col1\" >0.035</td>\n",
       "      <td id=\"T_8fb44_row8_col2\" class=\"data row8 col2\" >0.525</td>\n",
       "      <td id=\"T_8fb44_row8_col3\" class=\"data row8 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row8_col4\" class=\"data row8 col4\" >2.846</td>\n",
       "      <td id=\"T_8fb44_row8_col5\" class=\"data row8 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row8_col6\" class=\"data row8 col6\" >1.105</td>\n",
       "      <td id=\"T_8fb44_row8_col7\" class=\"data row8 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row9\" class=\"row_heading level0 row9\" >2014</th>\n",
       "      <td id=\"T_8fb44_row9_col0\" class=\"data row9 col0\" >27,663</td>\n",
       "      <td id=\"T_8fb44_row9_col1\" class=\"data row9 col1\" >0.007</td>\n",
       "      <td id=\"T_8fb44_row9_col2\" class=\"data row9 col2\" >0.801</td>\n",
       "      <td id=\"T_8fb44_row9_col3\" class=\"data row9 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row9_col4\" class=\"data row9 col4\" >1.119</td>\n",
       "      <td id=\"T_8fb44_row9_col5\" class=\"data row9 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row9_col6\" class=\"data row9 col6\" >0.665</td>\n",
       "      <td id=\"T_8fb44_row9_col7\" class=\"data row9 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row10\" class=\"row_heading level0 row10\" >2015</th>\n",
       "      <td id=\"T_8fb44_row10_col0\" class=\"data row10 col0\" >28,278</td>\n",
       "      <td id=\"T_8fb44_row10_col1\" class=\"data row10 col1\" >0.015</td>\n",
       "      <td id=\"T_8fb44_row10_col2\" class=\"data row10 col2\" >1.369</td>\n",
       "      <td id=\"T_8fb44_row10_col3\" class=\"data row10 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row10_col4\" class=\"data row10 col4\" >1.777</td>\n",
       "      <td id=\"T_8fb44_row10_col5\" class=\"data row10 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row10_col6\" class=\"data row10 col6\" >0.782</td>\n",
       "      <td id=\"T_8fb44_row10_col7\" class=\"data row10 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row11\" class=\"row_heading level0 row11\" >2016</th>\n",
       "      <td id=\"T_8fb44_row11_col0\" class=\"data row11 col0\" >29,947</td>\n",
       "      <td id=\"T_8fb44_row11_col1\" class=\"data row11 col1\" >0.020</td>\n",
       "      <td id=\"T_8fb44_row11_col2\" class=\"data row11 col2\" >1.213</td>\n",
       "      <td id=\"T_8fb44_row11_col3\" class=\"data row11 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row11_col4\" class=\"data row11 col4\" >1.135</td>\n",
       "      <td id=\"T_8fb44_row11_col5\" class=\"data row11 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row11_col6\" class=\"data row11 col6\" >1.370</td>\n",
       "      <td id=\"T_8fb44_row11_col7\" class=\"data row11 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row12\" class=\"row_heading level0 row12\" >2017</th>\n",
       "      <td id=\"T_8fb44_row12_col0\" class=\"data row12 col0\" >32,596</td>\n",
       "      <td id=\"T_8fb44_row12_col1\" class=\"data row12 col1\" >0.052</td>\n",
       "      <td id=\"T_8fb44_row12_col2\" class=\"data row12 col2\" >1.030</td>\n",
       "      <td id=\"T_8fb44_row12_col3\" class=\"data row12 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row12_col4\" class=\"data row12 col4\" >2.458</td>\n",
       "      <td id=\"T_8fb44_row12_col5\" class=\"data row12 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row12_col6\" class=\"data row12 col6\" >1.604</td>\n",
       "      <td id=\"T_8fb44_row12_col7\" class=\"data row12 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row13\" class=\"row_heading level0 row13\" >2018</th>\n",
       "      <td id=\"T_8fb44_row13_col0\" class=\"data row13 col0\" >36,337</td>\n",
       "      <td id=\"T_8fb44_row13_col1\" class=\"data row13 col1\" >0.107</td>\n",
       "      <td id=\"T_8fb44_row13_col2\" class=\"data row13 col2\" >0.585</td>\n",
       "      <td id=\"T_8fb44_row13_col3\" class=\"data row13 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row13_col4\" class=\"data row13 col4\" >4.464</td>\n",
       "      <td id=\"T_8fb44_row13_col5\" class=\"data row13 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row13_col6\" class=\"data row13 col6\" >1.641</td>\n",
       "      <td id=\"T_8fb44_row13_col7\" class=\"data row13 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row14\" class=\"row_heading level0 row14\" >2019</th>\n",
       "      <td id=\"T_8fb44_row14_col0\" class=\"data row14 col0\" >37,341</td>\n",
       "      <td id=\"T_8fb44_row14_col1\" class=\"data row14 col1\" >0.073</td>\n",
       "      <td id=\"T_8fb44_row14_col2\" class=\"data row14 col2\" >0.579</td>\n",
       "      <td id=\"T_8fb44_row14_col3\" class=\"data row14 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row14_col4\" class=\"data row14 col4\" >3.375</td>\n",
       "      <td id=\"T_8fb44_row14_col5\" class=\"data row14 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row14_col6\" class=\"data row14 col6\" >1.781</td>\n",
       "      <td id=\"T_8fb44_row14_col7\" class=\"data row14 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row15\" class=\"row_heading level0 row15\" >2020</th>\n",
       "      <td id=\"T_8fb44_row15_col0\" class=\"data row15 col0\" >37,810</td>\n",
       "      <td id=\"T_8fb44_row15_col1\" class=\"data row15 col1\" >0.105</td>\n",
       "      <td id=\"T_8fb44_row15_col2\" class=\"data row15 col2\" >0.618</td>\n",
       "      <td id=\"T_8fb44_row15_col3\" class=\"data row15 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row15_col4\" class=\"data row15 col4\" >3.085</td>\n",
       "      <td id=\"T_8fb44_row15_col5\" class=\"data row15 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row15_col6\" class=\"data row15 col6\" >3.330</td>\n",
       "      <td id=\"T_8fb44_row15_col7\" class=\"data row15 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row16\" class=\"row_heading level0 row16\" >2021</th>\n",
       "      <td id=\"T_8fb44_row16_col0\" class=\"data row16 col0\" >40,913</td>\n",
       "      <td id=\"T_8fb44_row16_col1\" class=\"data row16 col1\" >0.130</td>\n",
       "      <td id=\"T_8fb44_row16_col2\" class=\"data row16 col2\" >0.595</td>\n",
       "      <td id=\"T_8fb44_row16_col3\" class=\"data row16 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row16_col4\" class=\"data row16 col4\" >4.791</td>\n",
       "      <td id=\"T_8fb44_row16_col5\" class=\"data row16 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row16_col6\" class=\"data row16 col6\" >2.639</td>\n",
       "      <td id=\"T_8fb44_row16_col7\" class=\"data row16 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row17\" class=\"row_heading level0 row17\" >2022</th>\n",
       "      <td id=\"T_8fb44_row17_col0\" class=\"data row17 col0\" >45,519</td>\n",
       "      <td id=\"T_8fb44_row17_col1\" class=\"data row17 col1\" >0.077</td>\n",
       "      <td id=\"T_8fb44_row17_col2\" class=\"data row17 col2\" >0.656</td>\n",
       "      <td id=\"T_8fb44_row17_col3\" class=\"data row17 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row17_col4\" class=\"data row17 col4\" >2.755</td>\n",
       "      <td id=\"T_8fb44_row17_col5\" class=\"data row17 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row17_col6\" class=\"data row17 col6\" >2.064</td>\n",
       "      <td id=\"T_8fb44_row17_col7\" class=\"data row17 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row18\" class=\"row_heading level0 row18\" >2023</th>\n",
       "      <td id=\"T_8fb44_row18_col0\" class=\"data row18 col0\" >48,776</td>\n",
       "      <td id=\"T_8fb44_row18_col1\" class=\"data row18 col1\" >0.046</td>\n",
       "      <td id=\"T_8fb44_row18_col2\" class=\"data row18 col2\" >0.730</td>\n",
       "      <td id=\"T_8fb44_row18_col3\" class=\"data row18 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row18_col4\" class=\"data row18 col4\" >2.022</td>\n",
       "      <td id=\"T_8fb44_row18_col5\" class=\"data row18 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row18_col6\" class=\"data row18 col6\" >1.600</td>\n",
       "      <td id=\"T_8fb44_row18_col7\" class=\"data row18 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row19\" class=\"row_heading level0 row19\" >2024</th>\n",
       "      <td id=\"T_8fb44_row19_col0\" class=\"data row19 col0\" >51,171</td>\n",
       "      <td id=\"T_8fb44_row19_col1\" class=\"data row19 col1\" >0.059</td>\n",
       "      <td id=\"T_8fb44_row19_col2\" class=\"data row19 col2\" >0.529</td>\n",
       "      <td id=\"T_8fb44_row19_col3\" class=\"data row19 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row19_col4\" class=\"data row19 col4\" >2.737</td>\n",
       "      <td id=\"T_8fb44_row19_col5\" class=\"data row19 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row19_col6\" class=\"data row19 col6\" >1.730</td>\n",
       "      <td id=\"T_8fb44_row19_col7\" class=\"data row19 col7\" >0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_8fb44_level0_row20\" class=\"row_heading level0 row20\" >2025</th>\n",
       "      <td id=\"T_8fb44_row20_col0\" class=\"data row20 col0\" >12,885</td>\n",
       "      <td id=\"T_8fb44_row20_col1\" class=\"data row20 col1\" >0.041</td>\n",
       "      <td id=\"T_8fb44_row20_col2\" class=\"data row20 col2\" >0.677</td>\n",
       "      <td id=\"T_8fb44_row20_col3\" class=\"data row20 col3\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row20_col4\" class=\"data row20 col4\" >1.911</td>\n",
       "      <td id=\"T_8fb44_row20_col5\" class=\"data row20 col5\" >0.000</td>\n",
       "      <td id=\"T_8fb44_row20_col6\" class=\"data row20 col6\" >1.870</td>\n",
       "      <td id=\"T_8fb44_row20_col7\" class=\"data row20 col7\" >0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "年度回归参数已保存至: 'E:\\PBROE\\ch7\\analysis_results\\annual_regression_parameters.csv'\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T08:45:59.389517Z",
     "start_time": "2025-07-25T08:45:20.120792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 计算残差\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "\n",
    "# =================================================================== #\n",
    "#                           【1. 配置区域】                           #\n",
    "# =================================================================== #\n",
    "# 假设 dfpbroech7 变量已在之前的单元格中成功创建\n",
    "\n",
    "# --- 输出文件配置 ---\n",
    "OUTPUT_DIR = Path(r'E:\\PBROE\\ch7')\n",
    "OUTPUT_FILENAME = 'pbroe7.1Res.csv'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True) # 确保输出目录存在\n",
    "\n",
    "\n",
    "# =================================================================== #\n",
    "#                       【2. 数据清洗与预处理】                       #\n",
    "# =================================================================== #\n",
    "print(\"--- 步骤 1: 数据清洗与预处理 ---\")\n",
    "\n",
    "# 确保 dfpbroech7 存在\n",
    "if 'dfpbroech7' not in locals():\n",
    "    print(\"错误: 变量 'dfpbroech7' 未定义。请先运行数据加载的代码单元格。\")\n",
    "else:\n",
    "    df = dfpbroech7.copy()\n",
    "\n",
    "    # 1. 剔除ST,*ST股票 (假设 if_st=1 为ST)\n",
    "    df = df[df['if_st'] != 1]\n",
    "\n",
    "    # 2. 【回归模型特定清洗】剔除不符合回归条件的样本\n",
    "    # PB必须大于0才能取对数；ROE和ROIC不能过高/过低以避免极端值影响\n",
    "    df = df[(df['PB'] > 0) &\n",
    "            (df['roe_ttm'] <= 0.5) & (df['roe_ttm'] >= -0.1) &\n",
    "            (df['roic'] <= 0.5) & (df['roic'] >= -0.1)]\n",
    "\n",
    "    # 3. 剔除关键指标为空的记录\n",
    "    df.dropna(subset=['roe_ttm', 'roic', 'PB', 'indnme1'], inplace=True)\n",
    "\n",
    "    # 4. 计算因变量和自变量\n",
    "    df['lnPB'] = np.log(df['PB'])\n",
    "    # 新模型的第二个自变量：杠杆贡献度\n",
    "    df['leverage_spread'] = df['roe_ttm'] - df['roic']\n",
    "\n",
    "    print(f\"数据清洗后，剩余 {len(df)} 条有效记录用于回归分析。\")\n",
    "\n",
    "\n",
    "    # =================================================================== #\n",
    "    #              【3. 执行月度行业内回归与残差计算】                    #\n",
    "    # =================================================================== #\n",
    "    print(\"\\n--- 步骤 2: 执行基于ROIC分解模型的新回归与残差计算 ---\")\n",
    "\n",
    "    def calculate_residuals_roic_model(group):\n",
    "        \"\"\"\n",
    "        对给定的分组（某行业某月份），执行新的多元回归并计算标准化残差。\n",
    "        模型: ln(P/B) ~ 1 + roic + (roe_ttm - roic)\n",
    "        \"\"\"\n",
    "        # 行业内样本数过少，无法进行有意义的回归\n",
    "        if len(group) < 15: # 多元回归需要更多样本\n",
    "            group['residual_zscore'] = np.nan\n",
    "            return group\n",
    "\n",
    "        try:\n",
    "            # 准备回归的Y和X\n",
    "            # Y是市净率的自然对数\n",
    "            y = group['lnPB']\n",
    "            # X包含常数项、ROIC和杠杆贡献度\n",
    "            X = group[['roic', 'leverage_spread']]\n",
    "            X = sm.add_constant(X) # 添加常数项\n",
    "\n",
    "            # 执行OLS回归\n",
    "            model = sm.OLS(y, X, missing='drop').fit()\n",
    "\n",
    "            # 获取残差\n",
    "            residuals = model.resid\n",
    "\n",
    "            # 计算残差的均值和标准差\n",
    "            resid_mean = residuals.mean()\n",
    "            resid_std = residuals.std()\n",
    "\n",
    "            # 标准化残差 (Z-score)\n",
    "            if resid_std > 1e-6: # 避免除以零\n",
    "                group['residual_zscore'] = (residuals - resid_mean) / resid_std\n",
    "            else:\n",
    "                group['residual_zscore'] = 0.0\n",
    "\n",
    "        except Exception as e:\n",
    "            # 如果回归出错，则将残差设为空值\n",
    "            group['residual_zscore'] = np.nan\n",
    "\n",
    "        return group\n",
    "\n",
    "    # 按月份和行业分组，应用新的回归函数\n",
    "    regression_results_df = df.groupby(['trdmnt', 'indnme1'], group_keys=False).apply(calculate_residuals_roic_model)\n",
    "\n",
    "    # 清除回归失败或无法计算残差的记录\n",
    "    regression_results_df.dropna(subset=['residual_zscore'], inplace=True)\n",
    "\n",
    "    print(f\"回归与残差计算完成，共得到 {len(regression_results_df)} 条有效记录。\")\n",
    "\n",
    "\n",
    "    # =================================================================== #\n",
    "    #                       【4. 格式化并保存结果】                       #\n",
    "    # =================================================================== #\n",
    "    print(\"\\n--- 步骤 3: 格式化并保存最终数据文件 ---\")\n",
    "\n",
    "    if not regression_results_df.empty:\n",
    "        # 在这里，我们直接使用回归结果的DataFrame，它已经包含了所有需要的列\n",
    "        final_data = regression_results_df.copy()\n",
    "\n",
    "        # 【已修复】使用正确的日期格式 '%Y-%m' 来解析 trdmnt 列\n",
    "        final_data['调入日期'] = pd.to_datetime(final_data['trdmnt'], format='%Y-%m') + pd.DateOffset(months=1)\n",
    "        final_data['调入日期'] = final_data['调入日期'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "        # 选择最终需要的列\n",
    "        output_columns = ['调入日期', 'stkcd', 'shortname', 'indnme1', 'roe_ttm', 'roic', 'PB', 'residual_zscore']\n",
    "        final_portfolio_data = final_data[output_columns]\n",
    "\n",
    "        # 保存到CSV文件\n",
    "        output_path = OUTPUT_DIR / OUTPUT_FILENAME\n",
    "        final_portfolio_data.to_csv(output_path, index=False, encoding='utf-8-sig', float_format='%.6f')\n",
    "\n",
    "        print(f\"\\n策略数据已成功生成并保存为 '{output_path}'。\")\n",
    "        print(\"该文件包含了基于新模型的标准化残差，可用于后续策略构建。\")\n",
    "    else:\n",
    "        print(\"\\n未能计算出任何有效残差，无法生成数据文件。\")\n",
    "\n"
   ],
   "id": "80f9fd4cd73018fa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 步骤 1: 数据清洗与预处理 ---\n",
      "数据清洗后，剩余 582202 条有效记录用于回归分析。\n",
      "\n",
      "--- 步骤 2: 执行基于ROIC分解模型的新回归与残差计算 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3440\\749038853.py:95: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  regression_results_df = df.groupby(['trdmnt', 'indnme1'], group_keys=False).apply(calculate_residuals_roic_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回归与残差计算完成，共得到 528228 条有效记录。\n",
      "\n",
      "--- 步骤 3: 格式化并保存最终数据文件 ---\n",
      "\n",
      "策略数据已成功生成并保存为 'E:\\PBROE\\ch7\\pbroe7.1Res.csv'。\n",
      "该文件包含了基于新模型的标准化残差，可用于后续策略构建。\n",
      "\n",
      "文件预览（按残差升序排列）：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "              调入日期   stkcd shortname           indnme1   roe_ttm      roic  \\\n",
       "18150   2024-10-01  000413      东旭光电  计算机、通信和其他电子设备制造业 -0.071403 -0.003696   \n",
       "18149   2024-09-01  000413      东旭光电  计算机、通信和其他电子设备制造业 -0.077396 -0.005870   \n",
       "428544  2024-07-01  600277      亿利洁能      化学原料和化学制品制造业 -0.035919  0.000200   \n",
       "18148   2024-08-01  000413      东旭光电  计算机、通信和其他电子设备制造业 -0.077396 -0.005870   \n",
       "428543  2024-06-01  600277      亿利洁能      化学原料和化学制品制造业 -0.030474 -0.006384   \n",
       "\n",
       "              PB  residual_zscore  \n",
       "18150   0.096286        -6.201155  \n",
       "18149   0.096286        -5.514598  \n",
       "428544  0.071005        -5.027637  \n",
       "18148   0.158742        -4.598220  \n",
       "428543  0.142010        -4.216615  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>调入日期</th>\n",
       "      <th>stkcd</th>\n",
       "      <th>shortname</th>\n",
       "      <th>indnme1</th>\n",
       "      <th>roe_ttm</th>\n",
       "      <th>roic</th>\n",
       "      <th>PB</th>\n",
       "      <th>residual_zscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18150</th>\n",
       "      <td>2024-10-01</td>\n",
       "      <td>000413</td>\n",
       "      <td>东旭光电</td>\n",
       "      <td>计算机、通信和其他电子设备制造业</td>\n",
       "      <td>-0.071403</td>\n",
       "      <td>-0.003696</td>\n",
       "      <td>0.096286</td>\n",
       "      <td>-6.201155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18149</th>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>000413</td>\n",
       "      <td>东旭光电</td>\n",
       "      <td>计算机、通信和其他电子设备制造业</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.005870</td>\n",
       "      <td>0.096286</td>\n",
       "      <td>-5.514598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428544</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>600277</td>\n",
       "      <td>亿利洁能</td>\n",
       "      <td>化学原料和化学制品制造业</td>\n",
       "      <td>-0.035919</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.071005</td>\n",
       "      <td>-5.027637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18148</th>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>000413</td>\n",
       "      <td>东旭光电</td>\n",
       "      <td>计算机、通信和其他电子设备制造业</td>\n",
       "      <td>-0.077396</td>\n",
       "      <td>-0.005870</td>\n",
       "      <td>0.158742</td>\n",
       "      <td>-4.598220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428543</th>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>600277</td>\n",
       "      <td>亿利洁能</td>\n",
       "      <td>化学原料和化学制品制造业</td>\n",
       "      <td>-0.030474</td>\n",
       "      <td>-0.006384</td>\n",
       "      <td>0.142010</td>\n",
       "      <td>-4.216615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-25T09:40:47.469433Z",
     "start_time": "2025-07-25T09:40:42.793571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# pbroe7_backtest_engine.py\n",
    "# 一个为PB-ROE系列策略设计的、支持分组回测的通用引擎\n",
    "# 版本：全向量化单进程版 (高性能、高稳定性)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =================================================================== #\n",
    "#                       【1. 核心回测模块】                         #\n",
    "# =================================================================== #\n",
    "\n",
    "def run_grouped_backtest_vectorized(config):\n",
    "    \"\"\"\n",
    "    (核心函数) 使用全向量化方法，对所有分组一次性完成回测。\n",
    "    \"\"\"\n",
    "    print(\"--- 步骤 1: 加载数据 ---\")\n",
    "    try:\n",
    "        # 加载策略分组数据\n",
    "        strategy_df = pd.read_csv(config['RESIDUAL_FILE'])\n",
    "        strategy_df['调入日期'] = pd.to_datetime(strategy_df['调入日期'])\n",
    "        strategy_df['stkcd'] = strategy_df['stkcd'].astype(str).str.zfill(6)\n",
    "\n",
    "        # 加载收益率数据\n",
    "        returns_df = pd.read_csv(config['RETURNS_FILE'], dtype={'Stkcd': str})\n",
    "        returns_df.rename(columns={'Stkcd': 'stkcd', 'Trdmnt': 'date', 'Mretwd': 'stock_return'}, inplace=True)\n",
    "        returns_df['date'] = pd.to_datetime(returns_df['date'], format='%Y-%m')\n",
    "        returns_df['stock_return'] = pd.to_numeric(returns_df['stock_return'], errors='coerce')\n",
    "\n",
    "        # 加载基准数据\n",
    "        all_benchmarks_df = pd.read_csv(config['BENCHMARK_FILE'], dtype={'Indexcd': str})\n",
    "        benchmark_df = all_benchmarks_df[all_benchmarks_df['Indexcd'].str.zfill(6) == config['BENCHMARK_CODE']].copy()\n",
    "        benchmark_df['date'] = pd.to_datetime(benchmark_df['Month'], format='%Y-%m')\n",
    "        benchmark_df.rename(columns={'Idxrtn': 'benchmark_return'}, inplace=True)\n",
    "        benchmark_df = benchmark_df[['date', 'benchmark_return']]\n",
    "        print(\"所有数据加载成功。\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"错误: 找不到数据文件 {e.filename}。程序终止。\")\n",
    "        return None, None\n",
    "\n",
    "    print(\"\\n--- 步骤 2: 构建投资组合并执行回测 (向量化) ---\")\n",
    "\n",
    "    # 1. 创建分组\n",
    "    num_groups = config['NUM_GROUPS']\n",
    "    strategy_df['residual_group'] = strategy_df.groupby('调入日期')['residual_zscore'].transform(\n",
    "        lambda x: pd.qcut(x, num_groups, labels=False, duplicates='drop') + 1\n",
    "    )\n",
    "    strategy_df.dropna(subset=['residual_group'], inplace=True)\n",
    "    strategy_df['residual_group'] = strategy_df['residual_group'].astype(int)\n",
    "    strategy_df.rename(columns={'调入日期': 'date'}, inplace=True)\n",
    "\n",
    "    # 2. 筛选回测周期\n",
    "    start_date = pd.to_datetime(config['BACKTEST_START_DATE'])\n",
    "    end_date = pd.to_datetime(config['BACKTEST_END_DATE'])\n",
    "    strategy_df = strategy_df[(strategy_df['date'] >= start_date) & (strategy_df['date'] <= end_date)]\n",
    "\n",
    "    # 3. 【核心向量化步骤】将策略数据与收益数据合并\n",
    "    # inner merge确保只保留在持仓期内有收益数据的股票\n",
    "    merged_df = pd.merge(strategy_df[['date', 'stkcd', 'residual_group']], returns_df, on=['date', 'stkcd'], how='inner')\n",
    "\n",
    "    # 4. 【核心向量化步骤】一次性计算所有组在所有月份的平均收益\n",
    "    # groupby + mean 是Pandas中最高效的操作之一\n",
    "    monthly_returns = merged_df.groupby(['date', 'residual_group'])['stock_return'].mean()\n",
    "\n",
    "    # 5. 【核心向量化步骤】将结果从长格式转换为宽格式\n",
    "    # unstack() 将 'residual_group' 索引级别变成列\n",
    "    portfolio_returns_df = monthly_returns.unstack(level='residual_group')\n",
    "\n",
    "    # 重命名列以匹配后续格式\n",
    "    portfolio_returns_df.columns = [f'portfolio_return_g{int(col)}' for col in portfolio_returns_df.columns]\n",
    "\n",
    "    # 填充缺失月份（即当月该组无持仓或无收益数据），确保时间序列连续\n",
    "    all_months_index = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "    portfolio_returns_df = portfolio_returns_df.reindex(all_months_index, fill_value=0.0)\n",
    "\n",
    "    print(f\"向量化回测完成，已生成 {len(portfolio_returns_df)} 条月度收益记录。\\n\")\n",
    "\n",
    "    return portfolio_returns_df, benchmark_df\n",
    "\n",
    "\n",
    "# =================================================================== #\n",
    "#                       【2. 绩效计算与保存】                         #\n",
    "# =================================================================== #\n",
    "\n",
    "def calculate_performance_and_save(portfolio_returns_df, benchmark_df, config):\n",
    "    \"\"\"为所有分组计算绩效并保存结果。\"\"\"\n",
    "    print(\"--- 步骤 3: 计算并保存所有分组的绩效 ---\")\n",
    "\n",
    "    output_dir = config['OUTPUT_DIR']\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    returns_output_file = output_dir / f\"{config['STRATEGY_NAME']}_returns.csv\"\n",
    "    performance_output_file = output_dir / f\"{config['STRATEGY_NAME']}_performance.csv\"\n",
    "\n",
    "    num_groups = config['NUM_GROUPS']\n",
    "    risk_free_rate = config['RISK_FREE_RATE']\n",
    "\n",
    "    all_metrics = []\n",
    "    # 合并基准收益\n",
    "    final_returns_df = portfolio_returns_df.join(benchmark_df.set_index('date'), how='left').fillna(0)\n",
    "\n",
    "    for group_id in range(1, num_groups + 1):\n",
    "        return_col = f'portfolio_return_g{group_id}'\n",
    "        if return_col not in final_returns_df.columns: continue\n",
    "\n",
    "        final_returns_df[f'cumulative_return_g{group_id}'] = (1 + final_returns_df[return_col]).cumprod()\n",
    "        total_months = len(final_returns_df)\n",
    "        final_cumulative_return = final_returns_df[f'cumulative_return_g{group_id}'].iloc[-1]\n",
    "        annualized_return = final_cumulative_return ** (12 / total_months) - 1\n",
    "        annualized_volatility = final_returns_df[return_col].std() * np.sqrt(12)\n",
    "        sharpe_ratio = (annualized_return - risk_free_rate) / annualized_volatility if annualized_volatility != 0 else 0\n",
    "        rolling_max = final_returns_df[f'cumulative_return_g{group_id}'].expanding().max()\n",
    "        drawdown = (final_returns_df[f'cumulative_return_g{group_id}'] - rolling_max) / rolling_max\n",
    "        max_drawdown = drawdown.min()\n",
    "        annualized_benchmark_return = (1 + final_returns_df['benchmark_return']).prod() ** (12 / total_months) - 1\n",
    "        excess_return = final_returns_df[return_col] - final_returns_df['benchmark_return']\n",
    "        annualized_excess_return = annualized_return - annualized_benchmark_return\n",
    "        tracking_error = excess_return.std() * np.sqrt(12)\n",
    "        information_ratio = annualized_excess_return / tracking_error if tracking_error != 0 else 0\n",
    "        metrics = {'group': f\"Group {group_id}\", '年化收益率': annualized_return, '年化波动率': annualized_volatility, '夏普比率': sharpe_ratio, '最大回撤': max_drawdown, '累计收益率': final_cumulative_return - 1, '年化超额收益率': annualized_excess_return, '信息比率': information_ratio, '跟踪误差': tracking_error}\n",
    "        all_metrics.append(metrics)\n",
    "\n",
    "    performance_df = pd.DataFrame(all_metrics)\n",
    "    performance_df.loc['基准 (沪深300)', '年化收益率'] = annualized_benchmark_return\n",
    "\n",
    "    # 整理要保存的列\n",
    "    final_returns_df.reset_index(inplace=True)\n",
    "    final_returns_df.rename(columns={'index': 'date'}, inplace=True)\n",
    "    cols_to_save = ['date', 'benchmark_return'] + [f'portfolio_return_g{i}' for i in range(1, num_groups + 1) if f'portfolio_return_g{i}' in final_returns_df.columns] + [f'cumulative_return_g{i}' for i in range(1, num_groups + 1) if f'cumulative_return_g{i}' in final_returns_df.columns]\n",
    "    final_returns_df_to_save = final_returns_df[cols_to_save]\n",
    "\n",
    "    final_returns_df_to_save.to_csv(returns_output_file, index=False, encoding='utf-8-sig', float_format='%.6f')\n",
    "    print(f\"\\n所有分组的月度收益率详情已保存至: {returns_output_file}\")\n",
    "    performance_df.to_csv(performance_output_file, index=False, encoding='utf-8-sig', float_format='%.6f')\n",
    "    print(f\"所有分组的绩效指标已保存至: {performance_output_file}\")\n",
    "    print(f\"\\n--- {config['STRATEGY_NAME']} 各分组绩效简报 ---\")\n",
    "    print(performance_df.to_string())\n",
    "\n",
    "\n",
    "# =================================================================== #\n",
    "#                          【3. 主函数执行】                          #\n",
    "# =================================================================== #\n",
    "\n",
    "def main(config):\n",
    "    \"\"\"主执行函数\"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 步骤 1 & 2: 执行全向量化回测\n",
    "    portfolio_returns_df, benchmark_df = run_grouped_backtest_vectorized(config)\n",
    "\n",
    "    if portfolio_returns_df is None:\n",
    "        print(\"回测失败，程序终止。\")\n",
    "        return\n",
    "\n",
    "    # 步骤 3: 计算并保存绩效\n",
    "    calculate_performance_and_save(portfolio_returns_df, benchmark_df, config)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\n--- 所有任务完成！总耗时: {end_time - start_time:.2f} 秒 ---\")\n",
    "\n",
    "# =================================================================== #\n",
    "#                       【4. 脚本执行入口】                              #\n",
    "# =================================================================== #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- 定义 pbroe7.1 分组回测的配置 ---\n",
    "    CONFIG_PBROE7_GROUPED = {\n",
    "        # --- 策略与输出配置 ---\n",
    "        \"STRATEGY_NAME\": \"pbroe7.1_grouped_backtest_vectorized\",\n",
    "        \"OUTPUT_DIR\": Path(\"E:/PBROE/ch7/backtest_results\"),\n",
    "\n",
    "        # --- 输入文件路径 ---\n",
    "        \"RESIDUAL_FILE\": Path(\"E:/PBROE/ch7/pbroe7.1Res.csv\"),\n",
    "        \"RETURNS_FILE\": Path(\"E:/PBROE/data/TRDNEW_Mnth.csv\"),\n",
    "        \"BENCHMARK_FILE\": Path(\"E:/PBROE/data/benchmark_indices.csv\"),\n",
    "\n",
    "        # --- 策略核心参数 ---\n",
    "        \"NUM_GROUPS\": 10,\n",
    "\n",
    "        # --- 通用回测参数 ---\n",
    "        \"BACKTEST_START_DATE\": '2010-05-01',\n",
    "        \"BACKTEST_END_DATE\": '2025-04-30',\n",
    "        \"BENCHMARK_CODE\": '000300',\n",
    "        \"RISK_FREE_RATE\": 0.03\n",
    "    }\n",
    "\n",
    "    # --- 执行回测 ---\n",
    "    # 调用主函数，并传入配置字典\n",
    "    main(CONFIG_PBROE7_GROUPED)\n"
   ],
   "id": "631ff4f782d1a920",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 步骤 1: 加载数据 ---\n",
      "所有数据加载成功。\n",
      "\n",
      "--- 步骤 2: 构建投资组合并执行回测 (向量化) ---\n",
      "向量化回测完成，已生成 180 条月度收益记录。\n",
      "\n",
      "--- 步骤 3: 计算并保存所有分组的绩效 ---\n",
      "\n",
      "所有分组的月度收益率详情已保存至: E:\\PBROE\\ch7\\backtest_results\\pbroe7.1_grouped_backtest_vectorized_returns.csv\n",
      "所有分组的绩效指标已保存至: E:\\PBROE\\ch7\\backtest_results\\pbroe7.1_grouped_backtest_vectorized_performance.csv\n",
      "\n",
      "--- pbroe7.1_grouped_backtest_vectorized 各分组绩效简报 ---\n",
      "               group     年化收益率     年化波动率      夏普比率      最大回撤     累计收益率   年化超额收益率      信息比率      跟踪误差\n",
      "0            Group 1  0.149185  0.253464  0.470224 -0.330524  7.050988  0.135329  0.915515  0.147818\n",
      "1            Group 2  0.137539  0.256172  0.419791 -0.365079  5.910258  0.123683  0.748992  0.165133\n",
      "2            Group 3  0.130207  0.261433  0.383300 -0.363842  5.271505  0.116352  0.664933  0.174983\n",
      "3            Group 4  0.108281  0.269247  0.290741 -0.446471  3.674642  0.094425  0.510414  0.184998\n",
      "4            Group 5  0.103705  0.276182  0.266872 -0.465326  3.393355  0.089850  0.469865  0.191224\n",
      "5            Group 6  0.083525  0.277845  0.192643 -0.522265  2.331074  0.069669  0.357808  0.194712\n",
      "6            Group 7  0.070307  0.277616  0.145188 -0.534529  1.770915  0.056451  0.282195  0.200043\n",
      "7            Group 8  0.052204  0.282355  0.078639 -0.594114  1.145361  0.038349  0.187623  0.204392\n",
      "8            Group 9  0.047423  0.285146  0.061103 -0.637111  1.003707  0.033568  0.159997  0.209802\n",
      "9           Group 10 -0.010598  0.286498 -0.141704 -0.759097 -0.147699 -0.024453 -0.113346  0.215741\n",
      "基准 (沪深300)       NaN  0.013856       NaN       NaN       NaN       NaN       NaN       NaN       NaN\n",
      "\n",
      "--- 所有任务完成！总耗时: 4.65 秒 ---\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#计算残差时序分位数\n",
    "\n",
    "\n"
   ],
   "id": "ce1d777ca6256e4c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py312] *",
   "language": "python",
   "name": "conda-env-py312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
